{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: SVM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbde841c2efb4244ac10111fe906e356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from seqmm.pybayopt import GPEISklearn\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_breast_cancer()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target\n",
    "\n",
    "ParaSpace = {'C':     {'Type': 'continuous', 'Range': [-6, 16], 'Wrapper': np.exp2}, \n",
    "             'gamma': {'Type': 'continuous', 'Range': [-16, 6], 'Wrapper': np.exp2}}\n",
    "\n",
    "estimator = svm.SVC()\n",
    "score_metric = make_scorer(accuracy_score, True)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, time_out = 10, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import signal\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from spearmint.ExperimentGrid import GridMap\n",
    "import spearmint.chooser.GPEIOptChooser as module\n",
    "grid_size = 20000\n",
    "\n",
    "\n",
    "def spmint_opt(chooser, grid, values, grid_status):\n",
    "    \n",
    "    ## The status of jobs, 0 - candidate, 1 - pending, 2 - complete. \n",
    "    ## Here we only have two status: 0 or 2 available. \n",
    "    job_id = chooser.next(grid, np.squeeze(values), [],\n",
    "                          np.nonzero(grid_status == 0)[0],\n",
    "                          np.nonzero(grid_status == 1)[0],\n",
    "                          np.nonzero(grid_status == 2)[0])\n",
    "    return job_id\n",
    "\n",
    "\n",
    "ParaSpace = {'booster':          {'Type': 'categorical', 'Mapping': ['gbtree', 'gblinear']},\n",
    "             'max_depth':        {'Type': 'integer',     'Mapping': np.linspace(2,10,9)}, \n",
    "             'n_estimators':     {'Type': 'integer',     'Mapping': np.linspace(100,500,401)},\n",
    "             'min_child_weight': {'Type': 'integer',     'Mapping': np.linspace(1,100,100)},\n",
    "             'subsample':        {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'colsample_bytree': {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'learning_rate':    {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'gamma':            {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_lambda':       {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_alpha':         {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x}}\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "estimator = xgb.XGBRegressor()\n",
    "score_metric = make_scorer(mean_squared_error, False)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "def obj_func(cfg):\n",
    "    next_params = pd.DataFrame(np.array([cfg]), columns = ParaSpace)\n",
    "    parameters = {}\n",
    "    for item, values in ParaSpace.items():\n",
    "        if (values['Type']==\"continuous\"):\n",
    "            parameters[item] = values['Wrapper'](float(next_params[item].iloc[0]))\n",
    "        elif (values['Type']==\"integer\"):\n",
    "            parameters[item] = int(next_params[item].iloc[0]) \n",
    "        elif (values['Type']==\"categorical\"):\n",
    "            parameters[item] = next_params[item][0]\n",
    "    estimator.set_params(**parameters)\n",
    "    out = cross_val_score(estimator, x, y, cv = cv)\n",
    "    score = np.mean(out)\n",
    "\n",
    "    return -score, score, score\n",
    "    \n",
    "dt = datasets.load_diabetes()\n",
    "sx = MinMaxScaler()\n",
    "sy = MinMaxScaler()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = sy.fit_transform(dt.target.reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Runs = 100\n",
    "Rand_Seed = 1\n",
    "variables = {}\n",
    "np.random.seed(Rand_Seed)\n",
    "factor_number = len(ParaSpace)\n",
    "for i, label in enumerate(ParaSpace.keys()):\n",
    "    if ParaSpace[label]['Type'] ==\"continuous\":\n",
    "        variables[label] =  collections.OrderedDict({'name': label, \n",
    "                         'type':'float',\n",
    "                         'min': ParaSpace[label]['Range'][0],\n",
    "                         'max': ParaSpace[label]['Range'][1],\n",
    "                         'size': 1})\n",
    "    elif ParaSpace[label]['Type'] ==\"integer\":\n",
    "        variables[label] = collections.OrderedDict({'name': label, \n",
    "                         'type':'int',\n",
    "                         'min': min(ParaSpace[label]['Mapping']),\n",
    "                         'max': max(ParaSpace[label]['Mapping']),\n",
    "                         'size': 1})\n",
    "    elif ParaSpace[label]['Type'] ==\"categorical\":\n",
    "        variables[label] = collections.OrderedDict({'name': label, \n",
    "                         'type':'enum',\n",
    "                         'options': ParaSpace[label]['Mapping'],\n",
    "                         'size': 1})\n",
    "\n",
    "param_unit = []; Params = []; Val = []; Test = []; Time = []\n",
    "file_dir = \"./Benchmark/temp/\" + str(time.time()) + str(np.random.rand(1)[0]) + \"/\"\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "\n",
    "chooser = module.init(file_dir, \"mcmc_iters=10\")\n",
    "vkeys = [k for k in variables]\n",
    "gmap = GridMap([variables[k] for k in vkeys], grid_size)\n",
    "grid = np.asarray(gmap.hypercube_grid(grid_size, 1)) \n",
    "values = np.zeros(grid_size) + np.nan\n",
    "grid_status = np.zeros(grid.shape[0])\n",
    "\n",
    "for i in range(np.int(Max_Runs)):\n",
    "    try:\n",
    "        job_id = spmint_opt(chooser, grid, values, grid_status)\n",
    "    except:\n",
    "        print('Spearmint Early Stop!')\n",
    "        break\n",
    "\n",
    "\n",
    "    if isinstance(job_id, tuple):\n",
    "        (job_id, candidate) = job_id\n",
    "        grid = np.vstack((grid, candidate))\n",
    "        grid_status = np.append(grid_status, 2)\n",
    "        values = np.append(values, np.zeros(1)+np.nan)\n",
    "        job_id = grid.shape[0]-1\n",
    "    else:\n",
    "        candidate = grid[job_id,:]\n",
    "        grid_status[job_id] = 2\n",
    "\n",
    "    print(job_id, candidate)\n",
    "    next_params = gmap.unit_to_list(candidate)\n",
    "    valacc, testacc, tm = obj_func(next_params)\n",
    "    values[job_id] = valacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmap.unit_to_list(np.array([1.,         0. ,        1.  ,       1. ,        1. ,        0.,\n",
    " 1.    ,     0.     ,    0.13944059 , 0.        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contour plot based on a thorough grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_num = 25\n",
    "xlist = np.linspace(-6, 16, grid_num)\n",
    "ylist = np.linspace(-16, 6, grid_num)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.zeros((grid_num,grid_num))\n",
    "for i, C in enumerate(xlist):\n",
    "    for j, gamma in enumerate(ylist):\n",
    "        estimator = svm.SVC(C=2**C,gamma = 2**gamma)\n",
    "        out = cross_val_score(estimator, x, y, cv = cv, scoring = score_metric)\n",
    "        Z[j,i] = np.mean(out)\n",
    "        \n",
    "levels = [0.2, 0.4, 0.8, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0]\n",
    "cp = plt.contourf(X, Y, Z, levels)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.scatter(np.log2(clf.logs.loc[:,['C']]), \n",
    "            np.log2(clf.logs.loc[:,['gamma']]), color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Xgboost for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from seqmm.pybayopt import GPEISklearn\n",
    "\n",
    "dt = datasets.load_diabetes()\n",
    "sx = MinMaxScaler()\n",
    "sy = MinMaxScaler()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = sy.fit_transform(dt.target.reshape([-1,1]))\n",
    "\n",
    "ParaSpace = {'booster':          {'Type': 'categorical', 'Mapping': ['gbtree', 'gblinear']},\n",
    "             'max_depth':        {'Type': 'integer',     'Mapping': np.linspace(2,10,9)}, \n",
    "             'n_estimators':     {'Type': 'integer',     'Mapping': np.linspace(100,500,401)},\n",
    "             'min_child_weight': {'Type': 'integer',     'Mapping': np.linspace(1,100,100)},\n",
    "             'subsample':        {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'colsample_bytree': {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'learning_rate':    {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'gamma':            {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_lambda':       {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_alpha':         {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x}}\n",
    "\n",
    "estimator = xgb.XGBRegressor()\n",
    "score_metric = make_scorer(mean_squared_error, False)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, scoring = score_metric, time_out = 30, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Example 3: Kmeans for Unsupervised Clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from seqmm.pybayopt import GPEISklearn\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_iris()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target.reshape([-1,1])\n",
    "\n",
    "ParaSpace = {'n_clusters':  {'Type': 'integer',    'Mapping': np.linspace(2,9,8)}, \n",
    "             'tol':         {'Type': 'continuous', 'Range': [-6, -3], 'Wrapper': lambda x: 10**x}}\n",
    "\n",
    "estimator = KMeans()\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r-tensorflow",
   "language": "python",
   "name": "r-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
