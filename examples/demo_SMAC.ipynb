{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: SVM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'scenario'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-157c162f4b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParaSpace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/lib/python3.7/site-packages/seqmm/pybayopt/bayopt_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0msearch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_para_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0msearch_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_time_consumed_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_end_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msearch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2_local/lib/python3.7/site-packages/seqmm/pybayopt/sk_smac.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, obj_func)\u001b[0m\n\u001b[1;32m    137\u001b[0m                          \"abort_on_first_run_crash\":False})\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMAC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtae_runner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintensifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtae_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pynisher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# turn off the limit for resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mincumbent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'scenario'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from seqmm.pybayopt import SMAC\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_breast_cancer()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target\n",
    "\n",
    "ParaSpace = {'C':     {'Type': 'continuous', 'Range': [-6, 16], 'Wrapper': np.exp2}, \n",
    "             'gamma': {'Type': 'continuous', 'Range': [-16, 6], 'Wrapper': np.exp2}}\n",
    "\n",
    "estimator = svm.SVC()\n",
    "score_metric = make_scorer(accuracy_score, True)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = SMAC(estimator, cv, ParaSpace, max_runs = 100, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SMAC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95b5ef4f10e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mSMAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SMAC'"
     ]
    }
   ],
   "source": [
    "import SMAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contour plot based on a thorough grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_num = 25\n",
    "xlist = np.linspace(-6, 16, grid_num)\n",
    "ylist = np.linspace(-16, 6, grid_num)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.zeros((grid_num,grid_num))\n",
    "for i, C in enumerate(xlist):\n",
    "    for j, gamma in enumerate(ylist):\n",
    "        estimator = svm.SVC(C=2**C,gamma = 2**gamma)\n",
    "        out = cross_val_score(estimator, x, y, cv = cv, scoring = score_metric)\n",
    "        Z[j,i] = np.mean(out)\n",
    "        \n",
    "levels = [0.2, 0.4, 0.8, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0]\n",
    "cp = plt.contourf(X, Y, Z, levels)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.scatter(np.log2(clf.logs.loc[:,['C']]), \n",
    "            np.log2(clf.logs.loc[:,['gamma']]), color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Xgboost for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from seqmm.pybayopt import SMACSklearn\n",
    "\n",
    "dt = datasets.load_diabetes()\n",
    "sx = MinMaxScaler()\n",
    "sy = MinMaxScaler()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = sy.fit_transform(dt.target.reshape([-1,1]))\n",
    "\n",
    "ParaSpace = {'booster':          {'Type': 'categorical', 'Mapping': ['gbtree', 'gblinear']},\n",
    "             'max_depth':        {'Type': 'integer',     'Mapping': np.linspace(2,10,9)}, \n",
    "             'n_estimators':     {'Type': 'integer',     'Mapping': np.linspace(100,500,401)},\n",
    "             'min_child_weight': {'Type': 'integer',     'Mapping': np.linspace(1,10,10)},\n",
    "             'subsample':        {'Type': 'continuous',  'Range': [0.1, 1],  'Wrapper': lambda x:x},\n",
    "             'colsample_bytree': {'Type': 'continuous',  'Range': [0.1, 1],  'Wrapper': lambda x:x},\n",
    "             'learning_rate':    {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'gamma':            {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_lambda':       {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x},\n",
    "             'reg_alpha':        {'Type': 'continuous',  'Range': [-5, 0], 'Wrapper': lambda x: 10**x}}\n",
    "\n",
    "estimator = xgb.XGBRegressor()\n",
    "score_metric = make_scorer(mean_squared_error, False)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = SMACSklearn(estimator, cv, ParaSpace, max_runs = 100, refit = True, scoring = score_metric, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Example 3: Kmeans for Unsupervised Clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from seqmm.pybayopt import SMACSklearn\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_iris()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target.reshape([-1,1])\n",
    "\n",
    "ParaSpace = {'n_clusters':  {'Type': 'integer',    'Mapping': np.linspace(2,9,8)}, \n",
    "             'tol':         {'Type': 'continuous', 'Range': [-6, -3], 'Wrapper': lambda x: 10**x}}\n",
    "\n",
    "estimator = KMeans()\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = SMACSklearn(estimator, cv, ParaSpace, max_runs = 100, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.plot_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
