%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{SeqMML}
\date{May 16, 2019}
\release{}
\author{Zebin Yang and Aijun Zhang}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


SeqMML is an open-source python package developed for automated machine learning (AutoML) with focus on hyperparameter optimization. Unlike traditional Batch or Bayesian optimization methods, we propose to use the sequential uniform designs with the following advantages:
\begin{itemize}
\item {} 
Representative sampling of hyperparameter space: uniformly distributed trials tend to have a better exploration of the hyperparameter space.

\item {} 
Free surrogate modeling: it is free from the meta-model estimation and acquisition optimization procedures.

\item {} 
Parallel computing: the expensive model evaluation procedure could be conducted in parallel.

\end{itemize}

\sphinxstylestrong{What is AutoML?}
\begin{itemize}
\item {} 
AutoML is to perform Automated Machine Learning model/algorithm selection and hyperparameter tuning.

\item {} 
It also targets progressive automation of data preprocessing, feature extraction/transformation, postprocessing and interpretation.

\item {} 
Hyperparameter optimization, a.k.a. (hyper) paramater tuning, plays a central role in AutoML pipelines.

\end{itemize}

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.800\linewidth]{{AutoML_v1}.png}\hspace*{\fill}}

\sphinxstylestrong{However, it is not easy.}
\begin{itemize}
\item {} 
Hyperparameters can be continuous, integer-valued or categorical, e.g. regularization parameters, kernel bandwidths, learning rate, tree depth, batch size, number of layers, type of activation.

\item {} 
AutoML is of combinatorial nature, therefore a challenging problem with curse of dimensionality.

\item {} 
Robustness and reproducibility of optimal configuration depend not only on the specific algorithm, but also on the specific dataset.

\end{itemize}


\chapter{Contents:}
\label{\detokenize{index:contents}}

\section{Installation}
\label{\detokenize{installation:installation}}\label{\detokenize{installation::doc}}

\subsection{Prerequisite}
\label{\detokenize{installation:prerequisite}}
The following environments are required for SeqMML package:
\begin{itemize}
\item {} 
Python 3 (anaconda is preferable)

\item {} 
SWIG \textgreater{}= 3.0

\item {} 
C++ compiler

\end{itemize}

The following commands can be helpful for installing the C++ compiler:
\begin{itemize}
\item {} 
\sphinxstylestrong{Linux}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{conda} \PYG{n}{install} \PYG{n}{gxx\PYGZus{}linux}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{64} \PYG{n}{gcc\PYGZus{}linux}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{64} \PYG{n}{swig}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Mac}

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n+nb}{open} \PYG{o}{/}\PYG{n}{Library}\PYG{o}{/}\PYG{n}{Developer}\PYG{o}{/}\PYG{n}{CommandLineTools}\PYG{o}{/}\PYG{n}{Packages}\PYG{o}{/}\PYG{n}{macOS\PYGZus{}SDK\PYGZus{}headers\PYGZus{}for\PYGZus{}macOS\PYGZus{}10}\PYG{o}{.}\PYG{l+m+mf}{14.}\PYG{n}{pkg}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
\sphinxstylestrong{Windows}

\end{itemize}

Microsoft Visual Studio 14.0 is required, see \sphinxhref{https://wiki.python.org/moin/WindowsCompilers\#Microsoft\_Visual\_C.2B-.2B-\_14.0\_with\_Visual\_Studio\_2015\_.28x86.2C\_x64.2C\_ARM.29}{python windows compliers} for details.


\subsection{Github installation}
\label{\detokenize{installation:github-installation}}
You can install the package by the following console command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pip} \PYG{n}{install} \PYG{n}{git}\PYG{o}{+}\PYG{n}{http}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{ZebinYang}\PYG{o}{/}\PYG{n}{seqmml}\PYG{o}{.}\PYG{n}{git}\PYG{o}{.}
\end{sphinxVerbatim}


\subsection{Manual installation}
\label{\detokenize{installation:manual-installation}}
If git is not available, you can manually install the package by downloading the source codes and then compiling it by hand:
\begin{itemize}
\item {} 
Download the source codes from \sphinxurl{http://github.com/ZebinYang/seqmml.git}.

\item {} 
unzip and switch to the root folder.

\item {} 
Run the following shell commands to finish installation.

\end{itemize}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{pip} \PYG{n}{install} \PYG{o}{\PYGZhy{}}\PYG{n}{r} \PYG{n}{requirements}\PYG{o}{.}\PYG{n}{txt}
\PYG{n}{python} \PYG{n}{setup}\PYG{o}{.}\PYG{n}{py} \PYG{n}{install}
\end{sphinxVerbatim}


\section{Sequential Uniform Design}
\label{\detokenize{pysequd:sequential-uniform-design}}\label{\detokenize{pysequd::doc}}
We advocate to reformulate AutoML as a kind of Computer Experiment for the purpose of maximizing ML prediction accuracy (\sphinxcite{resources:yang2019}).
Within Computer Experiment framework, we propose a novel SeqUD approach for algorithm selection and optimal hyperparameter configuration.


\subsection{Motivation}
\label{\detokenize{pysequd:motivation}}
Uniform designs is a frequently used space-filling design method, first proposed in the 1980s by Prof. Fang and Prof. Wang. It aims at covering the search space uniformly, as shown in the figure below.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.400\linewidth]{{Demo_UD}.png}\hspace*{\fill}}

However, it is still a one-shot design method, which has similar limitations as grid search and random search. Accordingly, we develop a sequential uniform design method, which enjoys the advantage of both batch design and sequential strategy.


\subsection{SeqUD Algorithm}
\label{\detokenize{pysequd:sequd-algorithm}}\begin{itemize}
\item {} 
Define the search space by converting individual hyperparameters (upon necessary transformation) into unit hypercube \(C = [0,1]^d\): linear mapping if continuous/integer-valued, one-hot encoding if categorical.

\item {} 
Start with a set of UD trials \(\theta \in C\) to evaluate ML modelâ€™s CV scores; find \(\hat\theta_0^*\).

\item {} 
Sequential refining strategy: for iterative step \(t=1,2,\ldots,T_{\max}\)
\begin{itemize}
\item {} 
Centered at \(\hat\theta^*_{t-1}\), define the search subspace with reduced range and increased granularity.

\item {} 
Find augmented UD in the subspace; train ML algorithm with new \(\theta\) samples and obtain CV scores.

\item {} 
Collect all trained \(\{\theta, \mbox{CV}(\theta)\}\), and find \(\hat\theta_t^{*}\).

\end{itemize}

\item {} 
Output the optimal \(\theta^*\) from all trained \(\{\theta, \mbox{CV}(\theta)\}\).

\end{itemize}


\subsection{Illustrative Demo}
\label{\detokenize{pysequd:illustrative-demo}}
The figure below shows a two-stage example of the SeqUDHO approach in a 2-D space. The circle points represent the initial uniform design via \(U_{20}(20^{2})\). The surrounding box serves as the subspace of interest centered on the optimal trial \(x^{*}_{1}\) at the first stage, which is denoted by a square point in green. At the second stage, new trial points are augmented to form a \(U_{20}(20^{2})\), denoted by the blue triangle points.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.500\linewidth]{{Demo_SeqUD}.png}\hspace*{\fill}}

The proposed approach is advantageous over the Bayesian optimization methods.
\begin{itemize}
\item {} 
Uniformly distributed trials can have a better exploration.

\item {} 
It is free from the meta-modeling and acquisition optimization.

\item {} 
At each stage, the algorithm could be conducted in parallel.

\end{itemize}

To generate such a augmented design, we have developed another package pyunidoe, which can be found in the git repository \sphinxurl{https://github.com/ZebinYang/pyunidoe.git}.


\subsection{Example Usage}
\label{\detokenize{pysequd:example-usage}}
\sphinxstylestrong{SVM for Classification}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k}{import} \PYG{n}{MinMaxScaler}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{cross\PYGZus{}val\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k}{import} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{,} \PYG{n}{accuracy\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SeqUD}

\PYG{n}{sx} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{dt} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}breast\PYGZus{}cancer}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sx}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{dt}\PYG{o}{.}\PYG{n}{target}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}     \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{score\PYGZus{}metric} \PYG{o}{=} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{(}\PYG{n}{accuracy\PYGZus{}score}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SeqUD}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{level\PYGZus{}number} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{max\PYGZus{}search\PYGZus{}iter} \PYG{o}{=} \PYG{l+m+mi}{30}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
          \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Batch methods}
\label{\detokenize{pybatdoe:batch-methods}}\label{\detokenize{pybatdoe::doc}}
Batch methods can generate all the experimental trials before conducting any experiments. See the following.


\subsection{Simple Strategies}
\label{\detokenize{pybatdoe:simple-strategies}}\begin{itemize}
\item {} 
\sphinxstylestrong{Grid Search (Grid)}: exhaustive search over grid combinations.

\item {} 
\sphinxstylestrong{Random Search (Rand)}: it is more flexible than grid search, when not all hyperparameters are equally important. Furthermore, new trials can be added without adjustment and the experiments can also be stopped any time (\sphinxcite{resources:bergstra2012}).

\item {} 
\sphinxstylestrong{Latin Hypercube Sampling (LHS)}: near-random sample (\sphinxcite{resources:mckay1978}).

\item {} 
\sphinxstylestrong{Sobol Sequence (Sobol)}: quasi-random low-discrepancy sequence (\sphinxcite{resources:sobol967}).

\end{itemize}

The figures below (\sphinxcite{resources:zhang2019}) present the demo sampling history of the four mentioned approaches, including Grid search (top left), Random search (top right), Latin hypercube (bottom left) and Sobol Sequence (bottom right).

\sphinxincludegraphics[width=0.450\linewidth]{{Demo_Grid}.png} \sphinxincludegraphics[width=0.450\linewidth]{{Demo_Rand}.png} \sphinxincludegraphics[width=0.450\linewidth]{{Demo_LHS}.png} \sphinxincludegraphics[width=0.450\linewidth]{{Demo_Sobol}.png}


\subsection{Pros and Cons}
\label{\detokenize{pybatdoe:pros-and-cons}}\begin{itemize}
\item {} 
Easy to be paralleled, trials can be generated without too much burden.

\item {} 
The information of existing experiments is not utilized, which is not efficient.

\item {} 
To select an appropriate number of design points is always difficult, with potential over-sampling and under-sampling problems.

\end{itemize}


\subsection{Example Usage}
\label{\detokenize{pybatdoe:example-usage}}
\sphinxstylestrong{Grid Search}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{GridSearch}

\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
       \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{GridSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
            \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{Random Search}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{RandSearch}

\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
       \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{RandSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
            \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{Latin Hypercube Sampling}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{LHSSearch}

\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
       \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{LHSSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
            \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{Sobol Sequence}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SobolSearch}

\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
       \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SobolSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
            \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Bayesian Optimization}
\label{\detokenize{pybayopt:bayesian-optimization}}\label{\detokenize{pybayopt::doc}}
In classical Bayesian optimization, trials are sequentially sampled one-point-at-a-time through
maximizing the expected improvement (EI). Letâ€™s see a univariate example.

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=0.900\linewidth]{{Demo_BO_eng}.png}\hspace*{\fill}}


\subsection{Classical BO Methods}
\label{\detokenize{pybayopt:classical-bo-methods}}\begin{itemize}
\item {} 
\sphinxstylestrong{GP-EI} (\sphinxcite{resources:snoek2012}): use Gaussian process as surrogate model and EI as acquisition function.

\item {} 
\sphinxstylestrong{SMAC} (\sphinxcite{resources:hutter2011}): use random forest as surrogate model and EI as acquisition function.

\item {} 
\sphinxstylestrong{TPE} (\sphinxcite{resources:bergstra2011}): abbreviation of Tree-structured Parzen Estimator. It also uses EI as acquisition function but non-parametric method is employed to model \(p(x|y)\) and \(p(y)\) (the prior is not of interest actually) instead of \(p(y|x)\).

\end{itemize}

The corresponding python implementations:
\begin{itemize}
\item {} 
\sphinxstylestrong{Spearmint (GP-EI)}: \sphinxurl{https://github.com/JasperSnoek/spearmint}

\item {} 
\sphinxstylestrong{Hyperopt (TPE)}: \sphinxurl{https://github.com/hyperopt/hyperopt}

\item {} 
\sphinxstylestrong{SMAC}: \sphinxurl{https://github.com/automl/SMAC3}

\end{itemize}


\subsection{Pros and Cons}
\label{\detokenize{pybayopt:pros-and-cons}}
\sphinxstylestrong{Strength}
\begin{itemize}
\item {} 
New experiments can be easily added and the number or experiments does not need to be prespecified.

\item {} 
Evaluation information can be utilized and thus make the optimization process more efficient as compared to one-shot batch designs.

\item {} 
The commonly used acquisition function can balance the two goals of exploration and exploitation.

\end{itemize}

\sphinxstylestrong{Limitation}
\begin{itemize}
\item {} 
The meta-modeling and acquisition function optimization are difficult for high-dimensional problems.

\item {} 
Lack uniformity considerations: algorithm can be trapped into local areas if without a good initialization.

\item {} 
Bayesian optimization are designed to select trials one-by-one, which is unnatural to perform parallelization (Note BO can be paralleled via proposing more than one trial at a time. However, these tricks, e.g., by assigning a average value to the pending trials, are not natural and may harm the optimization performance).

\end{itemize}


\subsection{Example Usage}
\label{\detokenize{pybayopt:example-usage}}
We provide an unified interface to call the GPEI, SMAC and TPE methods, base on their open source implementation of spearmint, hyperopt and smac3.

\sphinxstylestrong{GP-EI}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k}{import} \PYG{n}{MinMaxScaler}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k}{import} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{,} \PYG{n}{accuracy\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{GPEIOPT}

\PYG{n}{sx} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{dt} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}breast\PYGZus{}cancer}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sx}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{dt}\PYG{o}{.}\PYG{n}{target}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}     \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{score\PYGZus{}metric} \PYG{o}{=} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{(}\PYG{n}{accuracy\PYGZus{}score}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{clf} \PYG{o}{=} \PYG{n}{GPEIOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{scoring} \PYG{o}{=} \PYG{n}{score\PYGZus{}metric}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{SMAC}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k}{import} \PYG{n}{MinMaxScaler}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{cross\PYGZus{}val\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k}{import} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{,} \PYG{n}{accuracy\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SMACOPT}

\PYG{n}{sx} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{dt} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}breast\PYGZus{}cancer}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sx}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{dt}\PYG{o}{.}\PYG{n}{target}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}     \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{score\PYGZus{}metric} \PYG{o}{=} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{(}\PYG{n}{accuracy\PYGZus{}score}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SMACOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{scoring} \PYG{o}{=} \PYG{n}{score\PYGZus{}metric}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxstylestrong{TPE}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k}{import} \PYG{n}{MinMaxScaler}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{cross\PYGZus{}val\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k}{import} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{,} \PYG{n}{accuracy\PYGZus{}score}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{TPEOPT}

\PYG{n}{sx} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{dt} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}breast\PYGZus{}cancer}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sx}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{dt}\PYG{o}{.}\PYG{n}{target}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}     \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{score\PYGZus{}metric} \PYG{o}{=} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{(}\PYG{n}{accuracy\PYGZus{}score}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{clf} \PYG{o}{=} \PYG{n}{TPEOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{scoring} \PYG{o}{=} \PYG{n}{score\PYGZus{}metric}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{plot\PYGZus{}scores}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Examples}
\label{\detokenize{examples:examples}}\label{\detokenize{examples::doc}}
Here we give more example usage of this package.


\subsection{SeqUD for function optimization}
\label{\detokenize{examples:sequd-for-function-optimization}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SeqUD}

\PYG{k}{def} \PYG{n+nf}{cliff}\PYG{p}{(}\PYG{n}{parameters}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{x1} \PYG{o}{=} \PYG{n}{parameters}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
    \PYG{n}{x2} \PYG{o}{=} \PYG{n}{parameters}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}
    \PYG{n}{term1} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5}\PYG{o}{*}\PYG{n}{x1}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{o}{/}\PYG{l+m+mi}{100}
    \PYG{n}{term2} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5}\PYG{o}{*}\PYG{p}{(}\PYG{n}{x2}\PYG{o}{+}\PYG{l+m+mf}{0.03}\PYG{o}{*}\PYG{n}{x1}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}
    \PYG{n}{y} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp}\PYG{p}{(}\PYG{n}{term1} \PYG{o}{+} \PYG{n}{term2}\PYG{p}{)}
    \PYG{k}{return}  \PYG{n}{y}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x1}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{20}\PYG{p}{,}\PYG{l+m+mi}{20}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{x2}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SeqUD}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{level\PYGZus{}number} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fmin}\PYG{p}{(}\PYG{n}{cliff}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Working with Scikit-learn Pipeline}
\label{\detokenize{examples:working-with-scikit-learn-pipeline}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k}{import} \PYG{n}{samples\PYGZus{}generator}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}selection} \PYG{k}{import} \PYG{n}{SelectKBest}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{feature\PYGZus{}selection} \PYG{k}{import} \PYG{n}{f\PYGZus{}regression}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{pipeline} \PYG{k}{import} \PYG{n}{Pipeline}

\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SeqUD}

\PYG{n}{X}\PYG{p}{,} \PYG{n}{y} \PYG{o}{=} \PYG{n}{samples\PYGZus{}generator}\PYG{o}{.}\PYG{n}{make\PYGZus{}classification}\PYG{p}{(}
    \PYG{n}{n\PYGZus{}informative}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{n\PYGZus{}redundant}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{42}\PYG{p}{)}

\PYG{n}{anova\PYGZus{}filter} \PYG{o}{=} \PYG{n}{SelectKBest}\PYG{p}{(}\PYG{n}{f\PYGZus{}regression}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{n}{kernel}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{linear}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{anova\PYGZus{}svm} \PYG{o}{=} \PYG{n}{Pipeline}\PYG{p}{(}\PYG{p}{[}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{anova}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{anova\PYGZus{}filter}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{svc}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{clf}\PYG{p}{)}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{anova\PYGZus{}svm}\PYG{o}{.}\PYG{n}{set\PYGZus{}params}\PYG{p}{(}\PYG{n}{anova\PYGZus{}\PYGZus{}k}\PYG{o}{=}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{svc\PYGZus{}\PYGZus{}C}\PYG{o}{=}\PYG{o}{.}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{anova\PYGZus{}\PYGZus{}k}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}      \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{integer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}        \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Mapping}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}  \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{svc\PYGZus{}\PYGZus{}C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}        \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}     \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}
            \PYG{p}{\PYGZcb{}}

\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SeqUD}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{anova\PYGZus{}svm}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{X}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Different Types of Hyperparameters}
\label{\detokenize{examples:different-types-of-hyperparameters}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{xgboost} \PYG{k}{as} \PYG{n+nn}{xgb}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{k+kn}{from} \PYG{n+nn}{matplotlib} \PYG{k}{import} \PYG{n}{pylab} \PYG{k}{as} \PYG{n}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing} \PYG{k}{import} \PYG{n}{MinMaxScaler}
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k}{import} \PYG{n}{make\PYGZus{}scorer}\PYG{p}{,} \PYG{n}{mean\PYGZus{}squared\PYGZus{}error}
\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SeqUD}

\PYG{n}{dt} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}diabetes}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sx} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{sy} \PYG{o}{=} \PYG{n}{MinMaxScaler}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{sx}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{data}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{sy}\PYG{o}{.}\PYG{n}{fit\PYGZus{}transform}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{.}\PYG{n}{target}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{booster}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}          \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{categorical}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Mapping}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gbtree}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gblinear}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{max\PYGZus{}depth}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}        \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{integer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}     \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Mapping}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{9}\PYG{p}{,}\PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n\PYGZus{}estimators}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}     \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{integer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}     \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Mapping}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{100}\PYG{p}{,}\PYG{l+m+mi}{500}\PYG{p}{,}\PYG{l+m+mi}{401}\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{colsample\PYGZus{}bytree}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:}\PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{learning\PYGZus{}rate}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}    \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{o}{*}\PYG{o}{*}\PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gamma}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}            \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{o}{*}\PYG{o}{*}\PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{reg\PYGZus{}lambda}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}       \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{o}{*}\PYG{o}{*}\PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
             \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{reg\PYGZus{}alpha}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}        \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}  \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{l+m+mi}{10}\PYG{o}{*}\PYG{o}{*}\PYG{n}{x}\PYG{p}{\PYGZcb{}}\PYG{p}{\PYGZcb{}}

\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{xgb}\PYG{o}{.}\PYG{n}{XGBRegressor}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{sequd\PYGZus{}clf} \PYG{o}{=} \PYG{n}{SeqUD}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{level\PYGZus{}number} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{max\PYGZus{}search\PYGZus{}iter} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs}\PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,}
         \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{sequd\PYGZus{}clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Modules}
\label{\detokenize{modules:modules}}\label{\detokenize{modules::doc}}

\subsection{seqmml.pybatdoe}
\label{\detokenize{apidoc:seqmml-pybatdoe}}\label{\detokenize{apidoc::doc}}

\subsubsection{seqmml.pybatdoe.batch\_grid}
\label{\detokenize{apidoc:module-pybatdoe.batch_grid}}\label{\detokenize{apidoc:seqmml-pybatdoe-batch-grid}}\index{pybatdoe.batch\_grid (module)@\spxentry{pybatdoe.batch\_grid}\spxextra{module}}\index{GridSearch (class in pybatdoe.batch\_grid)@\spxentry{GridSearch}\spxextra{class in pybatdoe.batch\_grid}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybatdoe.batch_grid.GridSearch}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybatdoe.batch\_grid.}}\sphinxbfcode{\sphinxupquote{GridSearch}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{n\_jobs=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of grid search.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{GridSearch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{GridSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} 
\PYG{g+go}{             scoring=None, n\PYGZus{}jobs = None, refit=False, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybatdoe.batch\_rand}
\label{\detokenize{apidoc:module-pybatdoe.batch_rand}}\label{\detokenize{apidoc:seqmml-pybatdoe-batch-rand}}\index{pybatdoe.batch\_rand (module)@\spxentry{pybatdoe.batch\_rand}\spxextra{module}}\index{RandSearch (class in pybatdoe.batch\_rand)@\spxentry{RandSearch}\spxextra{class in pybatdoe.batch\_rand}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybatdoe.batch_rand.RandSearch}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybatdoe.batch\_rand.}}\sphinxbfcode{\sphinxupquote{RandSearch}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{n\_jobs=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of Random Search.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{RandSearch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{RandSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} 
\PYG{g+go}{             scoring=None, n\PYGZus{}jobs = None, refit=False, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybatdoe.batch\_lhs}
\label{\detokenize{apidoc:module-pybatdoe.batch_lhs}}\label{\detokenize{apidoc:seqmml-pybatdoe-batch-lhs}}\index{pybatdoe.batch\_lhs (module)@\spxentry{pybatdoe.batch\_lhs}\spxextra{module}}\index{LHSSearch (class in pybatdoe.batch\_lhs)@\spxentry{LHSSearch}\spxextra{class in pybatdoe.batch\_lhs}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybatdoe.batch_lhs.LHSSearch}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybatdoe.batch\_lhs.}}\sphinxbfcode{\sphinxupquote{LHSSearch}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{n\_jobs=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of Latin Hypercube Sampling.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{LHSSearch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{LHSSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} 
\PYG{g+go}{             scoring=None, n\PYGZus{}jobs = None, refit=False, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybatdoe.batch\_sobol}
\label{\detokenize{apidoc:module-pybatdoe.batch_sobol}}\label{\detokenize{apidoc:seqmml-pybatdoe-batch-sobol}}\index{pybatdoe.batch\_sobol (module)@\spxentry{pybatdoe.batch\_sobol}\spxextra{module}}\index{SobolSearch (class in pybatdoe.batch\_sobol)@\spxentry{SobolSearch}\spxextra{class in pybatdoe.batch\_sobol}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybatdoe.batch_sobol.SobolSearch}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybatdoe.batch\_sobol.}}\sphinxbfcode{\sphinxupquote{SobolSearch}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{n\_jobs=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of Sobol Sequence.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SobolSearch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SobolSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} 
\PYG{g+go}{             scoring=None, n\PYGZus{}jobs = None, refit=False, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybatdoe.batch\_ud}
\label{\detokenize{apidoc:module-pybatdoe.batch_ud}}\label{\detokenize{apidoc:seqmml-pybatdoe-batch-ud}}\index{pybatdoe.batch\_ud (module)@\spxentry{pybatdoe.batch\_ud}\spxextra{module}}\index{UDSearch (class in pybatdoe.batch\_ud)@\spxentry{UDSearch}\spxextra{class in pybatdoe.batch\_ud}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybatdoe.batch_ud.UDSearch}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybatdoe.batch\_ud.}}\sphinxbfcode{\sphinxupquote{UDSearch}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{level\_number=20}, \emph{max\_search\_iter=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{n\_jobs=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of Uniform Design.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{UDSearch}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{UDSearch}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{level\PYGZus{}number} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}search\PYGZus{}iter} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} 
\PYG{g+go}{             scoring=None, n\PYGZus{}jobs = None, refit=False, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{seqmml.pybayopt}
\label{\detokenize{apidoc:seqmml-pybayopt}}

\subsubsection{seqmml.pybayopt.bayopt\_gpei}
\label{\detokenize{apidoc:module-pybayopt.bayopt_gpei}}\label{\detokenize{apidoc:seqmml-pybayopt-bayopt-gpei}}\index{pybayopt.bayopt\_gpei (module)@\spxentry{pybayopt.bayopt\_gpei}\spxextra{module}}\index{GPEIOPT (class in pybayopt.bayopt\_gpei)@\spxentry{GPEIOPT}\spxextra{class in pybayopt.bayopt\_gpei}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybayopt.bayopt_gpei.GPEIOPT}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybayopt.bayopt\_gpei.}}\sphinxbfcode{\sphinxupquote{GPEIOPT}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{time\_out=10}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Interface of Gaussian Process - Expected Improvement (Bayesian Optimization).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{time\_out}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 10}}) \textendash{} The time out threshold (in seconds) for generating the next run.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{GPEIOPT}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{GPEIOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{time\PYGZus{}out} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{,} 
\PYG{g+go}{            estimator = estimator, cv = cv, scoring = None, refit = None, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybayopt.bayopt\_smac}
\label{\detokenize{apidoc:module-pybayopt.bayopt_smac}}\label{\detokenize{apidoc:seqmml-pybayopt-bayopt-smac}}\index{pybayopt.bayopt\_smac (module)@\spxentry{pybayopt.bayopt\_smac}\spxextra{module}}\index{SMACOPT (class in pybayopt.bayopt\_smac)@\spxentry{SMACOPT}\spxextra{class in pybayopt.bayopt\_smac}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybayopt.bayopt_smac.SMACOPT}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybayopt.bayopt\_smac.}}\sphinxbfcode{\sphinxupquote{SMACOPT}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Interface of SMAC (Bayesian Optimization).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SMACOPT}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SMACOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} 
\PYG{g+go}{            estimator = estimator, cv = cv, scoring = None, refit = None, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{seqmml.pybayopt.bayopt\_tpe}
\label{\detokenize{apidoc:module-pybayopt.bayopt_tpe}}\label{\detokenize{apidoc:seqmml-pybayopt-bayopt-tpe}}\index{pybayopt.bayopt\_tpe (module)@\spxentry{pybayopt.bayopt\_tpe}\spxextra{module}}\index{TPEOPT (class in pybayopt.bayopt\_tpe)@\spxentry{TPEOPT}\spxextra{class in pybayopt.bayopt\_tpe}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pybayopt.bayopt_tpe.TPEOPT}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pybayopt.bayopt\_tpe.}}\sphinxbfcode{\sphinxupquote{TPEOPT}}}{\emph{para\_space}, \emph{max\_runs=100}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{refit=False}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Interface of Hyperopt (Bayesian Optimization).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{TPEOPT}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{TPEOPT}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{estimator} \PYG{o}{=} \PYG{n}{estimator}\PYG{p}{,} \PYG{n}{cv} \PYG{o}{=} \PYG{n}{cv}\PYG{p}{,} \PYG{n}{scoring} \PYG{o}{=} \PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{refit} \PYG{o}{=} \PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{rand\PYGZus{}seed} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{verbose} \PYG{o}{=} \PYG{k+kc}{False}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{seqmml.pysequd}
\label{\detokenize{apidoc:seqmml-pysequd}}

\subsubsection{seqmml.pysequd.seqrand}
\label{\detokenize{apidoc:module-pysequd.seqrand}}\label{\detokenize{apidoc:seqmml-pysequd-seqrand}}\index{pysequd.seqrand (module)@\spxentry{pysequd.seqrand}\spxextra{module}}\index{SeqRand (class in pysequd.seqrand)@\spxentry{SeqRand}\spxextra{class in pysequd.seqrand}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.seqrand.SeqRand}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pysequd.seqrand.}}\sphinxbfcode{\sphinxupquote{SeqRand}}}{\emph{para\_space}, \emph{n\_iter\_per\_stage=20}, \emph{max\_runs=100}, \emph{n\_jobs=None}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{refit=None}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of random search in sequential version.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{level\_number}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 20}}) \textendash{} The positive integer which represent the number of levels in generating uniform design.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_search\_iter}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of iterations used to generate uniform design or augmented uniform design.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmm} \PYG{k}{import} \PYG{n}{SeqRand}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{Level\PYGZus{}Number} \PYG{o}{=} \PYG{l+m+mi}{20}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SeqRand}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{n\PYGZus{}iter\PYGZus{}per\PYGZus{}stage} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs} \PYG{o}{=} \PYG{k+kc}{None}\PYG{p}{,} 
\PYG{g+go}{             estimator = None, cv = None, scoring = None, refit = None, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}
\index{fit() (pysequd.seqrand.SeqRand method)@\spxentry{fit()}\spxextra{pysequd.seqrand.SeqRand method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.seqrand.SeqRand.fit}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fit}}}{\emph{x}, \emph{y=None}}{}
Run fit with all sets of parameters.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{x}} (\sphinxstyleliteralemphasis{\sphinxupquote{array}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{shape =}}\sphinxstyleliteralemphasis{\sphinxupquote{ {[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{n\_features}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} input variales.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{array}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{shape =}}\sphinxstyleliteralemphasis{\sphinxupquote{ {[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} or }}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{n\_output}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} target variable.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{fmin() (pysequd.seqrand.SeqRand method)@\spxentry{fmin()}\spxextra{pysequd.seqrand.SeqRand method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.seqrand.SeqRand.fmin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fmin}}}{\emph{wrapper\_func}}{}
Search the optimal value of a function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{func}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable function}}) \textendash{} the function to be optimized.

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_scores() (pysequd.seqrand.SeqRand method)@\spxentry{plot\_scores()}\spxextra{pysequd.seqrand.SeqRand method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.seqrand.SeqRand.plot_scores}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot\_scores}}}{}{}
Visualize the scores history.

\end{fulllineitems}


\end{fulllineitems}



\subsubsection{seqmml.pysequd.sequd}
\label{\detokenize{apidoc:module-pysequd.sequd}}\label{\detokenize{apidoc:seqmml-pysequd-sequd}}\index{pysequd.sequd (module)@\spxentry{pysequd.sequd}\spxextra{module}}\index{SeqUD (class in pysequd.sequd)@\spxentry{SeqUD}\spxextra{class in pysequd.sequd}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.sequd.SeqUD}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{pysequd.sequd.}}\sphinxbfcode{\sphinxupquote{SeqUD}}}{\emph{para\_space}, \emph{level\_number=20}, \emph{max\_runs=100}, \emph{max\_search\_iter=100}, \emph{n\_jobs=None}, \emph{estimator=None}, \emph{cv=None}, \emph{scoring=None}, \emph{refit=None}, \emph{rand\_seed=0}, \emph{verbose=False}}{}
Implementation of sequential uniform design.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{para\_space}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list of dictionaries}}) \textendash{} 
It has three types:
\begin{description}
\item[{Continuous: }] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{continuous}, and include the keys of \sphinxtitleref{Range} (a list with lower-upper elements pair) and
\sphinxtitleref{Wrapper}, a callable function for wrapping the values.

\item[{Integer:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{integer}, and include the keys of \sphinxtitleref{Mapping} (a list with all the sortted integer elements).

\item[{Categorical:}] \leavevmode
Specify \sphinxtitleref{Type} as \sphinxtitleref{categorical}, and include the keys of \sphinxtitleref{Mapping} (a list with all the possible categories).

\end{description}


\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{level\_number}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 20}}) \textendash{} The positive integer which represent the number of levels in generating uniform design.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_runs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of trials to be evaluated. When this values is reached, 
then the algorithm will stop.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{max\_search\_iter}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = 100}}) \textendash{} The maximum number of iterations used to generate uniform design or augmented uniform design.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{n\_jobs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} Number of jobs to run in parallel.
If -1 all CPUs are used. If 1 is given, no parallel computing code
is used at all, which is useful for debugging. See the package \sphinxtitleref{joblib} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{estimator}} (\sphinxstyleliteralemphasis{\sphinxupquote{estimator object}}) \textendash{} This is assumed to implement the scikit-learn estimator interface.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{cross-validation method}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{an sklearn object.}}) \textendash{} e.g., \sphinxtitleref{StratifiedKFold} and KFold{}` is used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{scoring}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list/tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{dict}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{None}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = None}}) \textendash{} A sklearn type scoring function. 
If None, the estimatorâ€™s default scorer (if available) is used. See the package \sphinxtitleref{sklearn} for details.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, or }}\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = True}}) \textendash{} It controls whether to refit an estimator using the best found parameters on the whole dataset.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rand\_seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=0}}) \textendash{} The random seed for optimization.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{boolean}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default = False}}) \textendash{} It controls whether the searching history will be printed.

\end{itemize}

\end{description}\end{quote}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{svm}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn} \PYG{k}{import} \PYG{n}{datasets}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{seqmml} \PYG{k}{import} \PYG{n}{SeqUD}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{model\PYGZus{}selection} \PYG{k}{import} \PYG{n}{KFold}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{iris} \PYG{o}{=} \PYG{n}{datasets}\PYG{o}{.}\PYG{n}{load\PYGZus{}iris}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{ParaSpace} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{C}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:}\PYG{p}{\PYGZob{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Type}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{continuous}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Range}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{p}{[}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{6}\PYG{p}{,} \PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Wrapper}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{:} \PYG{n}{np}\PYG{o}{.}\PYG{n}{exp2}\PYG{p}{\PYGZcb{}}\PYG{p}{,} 
\PYG{g+go}{           \PYGZsq{}gamma\PYGZsq{}: \PYGZob{}\PYGZsq{}Type\PYGZsq{}: \PYGZsq{}continuous\PYGZsq{}, \PYGZsq{}Range\PYGZsq{}: [\PYGZhy{}16, 6], \PYGZsq{}Wrapper\PYGZsq{}: np.exp2\PYGZcb{}\PYGZcb{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{Level\PYGZus{}Number} \PYG{o}{=} \PYG{l+m+mi}{20}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{estimator} \PYG{o}{=} \PYG{n}{svm}\PYG{o}{.}\PYG{n}{SVC}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cv} \PYG{o}{=} \PYG{n}{KFold}\PYG{p}{(}\PYG{n}{n\PYGZus{}splits}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{random\PYGZus{}state}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf} \PYG{o}{=} \PYG{n}{SeqUD}\PYG{p}{(}\PYG{n}{ParaSpace}\PYG{p}{,} \PYG{n}{level\PYGZus{}number} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{max\PYGZus{}runs} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{max\PYGZus{}search\PYGZus{}iter} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{n\PYGZus{}jobs}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} 
\PYG{g+go}{             estimator = None, cv = None, scoring = None, refit = None, rand\PYGZus{}seed = 0, verbose = False)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{clf}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{iris}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n}{iris}\PYG{o}{.}\PYG{n}{target}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{quote}\begin{description}
\item[{Variables}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_score\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} The best average cv score among the evaluated trials.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_params\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{dict}}) \textendash{} Parameters that reaches \sphinxtitleref{best\_score\_}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{best\_estimator\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{sklearn estimator}}) \textendash{} The estimator refitted based on the \sphinxtitleref{best\_params\_}. 
Not available if estimator = None or \sphinxtitleref{refit=False}.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{search\_time\_consumed\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for whole searching procedure.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{refit\_time\_}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} Seconds used for refitting the best model on the whole dataset.
Not available if estimator = None or \sphinxtitleref{refit=False}.

\end{itemize}

\end{description}\end{quote}
\index{fit() (pysequd.sequd.SeqUD method)@\spxentry{fit()}\spxextra{pysequd.sequd.SeqUD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.sequd.SeqUD.fit}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fit}}}{\emph{x}, \emph{y=None}}{}
Run fit with all sets of parameters.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{x}} (\sphinxstyleliteralemphasis{\sphinxupquote{array}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{shape =}}\sphinxstyleliteralemphasis{\sphinxupquote{ {[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{n\_features}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} input variales.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{array}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{shape =}}\sphinxstyleliteralemphasis{\sphinxupquote{ {[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} or }}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{n\_samples}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{n\_output}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} target variable.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{fmin() (pysequd.sequd.SeqUD method)@\spxentry{fmin()}\spxextra{pysequd.sequd.SeqUD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.sequd.SeqUD.fmin}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fmin}}}{\emph{wrapper\_func}}{}
Search the optimal value of a function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{func}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable function}}) \textendash{} the function to be optimized.

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_scores() (pysequd.sequd.SeqUD method)@\spxentry{plot\_scores()}\spxextra{pysequd.sequd.SeqUD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{apidoc:pysequd.sequd.SeqUD.plot_scores}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot\_scores}}}{}{}
Visualize the scores history.

\end{fulllineitems}


\end{fulllineitems}



\section{Resources}
\label{\detokenize{resources:resources}}\label{\detokenize{resources::doc}}

\subsection{Software}
\label{\detokenize{resources:software}}\begin{itemize}
\item {} 
Spearmint (GP-EI): \sphinxurl{https://github.com/JasperSnoek/spearmint}

\item {} 
Hyperopt (TPE): \sphinxurl{https://github.com/hyperopt/hyperopt}

\item {} 
SMAC: \sphinxurl{https://github.com/automl/SMAC3}

\item {} 
TPOP (AutoML based on genetic programming): \sphinxurl{https://github.com/EpistasisLab/tpot}

\item {} 
Bayesian optimization in PyTorch: \sphinxurl{https://github.com/pytorch/botorch}

\item {} 
HPOlib (another common interface to three BO methods): \sphinxurl{https://github.com/automl/HPOlib}

\item {} 
skopt (several methods for sequential model-based optimization): \sphinxurl{https://scikit-optimize.github.io}

\item {} 
auto-sklearn (Automated Machine Learning with scikit-learn): \sphinxurl{https://github.com/automl/auto-sklearn}

\item {} 
autokeras (AutoML for deep learning): \sphinxurl{https://github.com/keras-team/autokeras}

\item {} 
pyautoweka (AutoWeka in python): \sphinxurl{https://github.com/automl/pyautoweka}

\end{itemize}

To be added â€¦


\subsection{Reference}
\label{\detokenize{resources:reference}}
\begin{sphinxthebibliography}{Bergstra}
\bibitem[Bergstra2011]{resources:bergstra2011}
Bergstra J. S., Bardenet R., Bengio Y. and KÃ©gl B. (2011) Algorithms for hyper-parameter optimization. In Advances in Neural Information Processing Systems, pp. 2546\textendash{}2554.
\bibitem[Bergstra2012]{resources:bergstra2012}
Bergstra J. and Bengio Y. (2012). Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb): 281\textendash{}305.
\bibitem[Hutter2011]{resources:hutter2011}
Hutter F., Hoos H.H. and Leyton-Brown K. (2011) Sequential model-based optimization for general algorithm configuration. In International Conference on Learning and Intelligent Optimization, pp. 507\textendash{}523. Springer.
\bibitem[McKay1978]{resources:mckay1978}
McKay, M.D., Beckman, R.J. and Conover, W.J. (1979). Comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 21(2): 239-245.
\bibitem[Sobol967]{resources:sobol967}
Sobol,I.M. (1967), Distribution of points in a cube and approximate evaluation of integrals. Zh. Vych. Mat. Mat. Fiz. 7: 784\textendash{}802 (in Russian); U.S.S.R Comput. Maths. Math. Phys. 7: 86\textendash{}112 (in English)
\bibitem[Snoek2012]{resources:snoek2012}
Snoek J., Larochelle H. and Adams R.P. (2012). Practical bayesian optimization of machine learning algorithms. In Advances in Neural Information Processing Systems, pp. 2951\textendash{}2959.
\bibitem[Yang2019]{resources:yang2019}
Zebin Yang, Aijun Zhang and Ji Zhu. (2019) Hyperparameter Optimization via Sequential Uniform Designs. Submitted.
\bibitem[Zhang2019]{resources:zhang2019}
Zhang A.J. and Yang Z.B. (2019). Hyperparameter Tuning Methods in Automated Machine Learning. (In Chinese) Submitted.
\end{sphinxthebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{p}
\item\relax\sphinxstyleindexentry{pybatdoe.batch\_grid}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybatdoe.batch_grid}}
\item\relax\sphinxstyleindexentry{pybatdoe.batch\_lhs}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybatdoe.batch_lhs}}
\item\relax\sphinxstyleindexentry{pybatdoe.batch\_rand}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybatdoe.batch_rand}}
\item\relax\sphinxstyleindexentry{pybatdoe.batch\_sobol}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybatdoe.batch_sobol}}
\item\relax\sphinxstyleindexentry{pybatdoe.batch\_ud}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybatdoe.batch_ud}}
\item\relax\sphinxstyleindexentry{pybayopt.bayopt\_gpei}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybayopt.bayopt_gpei}}
\item\relax\sphinxstyleindexentry{pybayopt.bayopt\_smac}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybayopt.bayopt_smac}}
\item\relax\sphinxstyleindexentry{pybayopt.bayopt\_tpe}\sphinxstyleindexpageref{apidoc:\detokenize{module-pybayopt.bayopt_tpe}}
\item\relax\sphinxstyleindexentry{pysequd.seqrand}\sphinxstyleindexpageref{apidoc:\detokenize{module-pysequd.seqrand}}
\item\relax\sphinxstyleindexentry{pysequd.sequd}\sphinxstyleindexpageref{apidoc:\detokenize{module-pysequd.sequd}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}