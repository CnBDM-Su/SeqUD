{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008142039609053464"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyDOE import *\n",
    "x = lhs(n = 2, samples=6, criterion='centermaximin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5  , 0.5  , 0.5  ],\n",
       "       [0.75 , 0.25 , 0.75 ],\n",
       "       [0.25 , 0.75 , 0.25 ],\n",
       "       [0.375, 0.375, 0.625],\n",
       "       [0.875, 0.875, 0.125]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sobol_seq\n",
    "sobol_seq.i4_sobol_generate(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pylab as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from pyDOE import lhs\n",
    "\n",
    "class LHSSklearn():\n",
    "    \"\"\" \n",
    "    Sklearn Hyperparameter optimization interface based on Latin Hypercube Sampling. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    :type  estimator: estimator object\n",
    "    :param estimator: This is assumed to implement the scikit-learn estimator interface.\n",
    "    \n",
    "    :type  cv: cross-validation method, an sklearn object.\n",
    "    :param cv: e.g., `StratifiedKFold` and KFold` is used.\n",
    "    \n",
    "    :type  para_space: dict or list of dictionaries\n",
    "    :param para_space: It has three types:\n",
    "    \n",
    "        Continuous: \n",
    "            Specify `Type` as `continuous`, and include the keys of `Range` (a list with lower-upper elements pair) and\n",
    "            `Wrapper`, a callable function for wrapping the values.  \n",
    "        Integer:\n",
    "            Specify `Type` as `integer`, and include the keys of `Mapping` (a list with all the sortted integer elements).\n",
    "        Categorical:\n",
    "            Specify `Type` as `categorical`, and include the keys of `Mapping` (a list with all the possible categories).\n",
    "    \n",
    "    :type max_runs: int\n",
    "    :param max_runs: The maximum number of trials to be evaluated. When this values is reached, \n",
    "        then the algorithm will stop. \n",
    "        \n",
    "    :type scoring: string, callable, list/tuple, dict or None, optional, default: None\n",
    "    :param scoring: A sklearn type scoring function. \n",
    "        If None, the estimator's default scorer (if available) is used. See the package `sklearn` for details.\n",
    "    \n",
    "    :type refit: boolean, or string, optional, default=True\n",
    "    :param refit: It controls whether to refit an estimator using the best found parameters on the whole dataset.\n",
    "    \n",
    "    :type rand_seed: int, optional, default=0\n",
    "    :param rand_seed: The random seed for optimization.\n",
    "    \n",
    "    :type verbose: boolean, optional, default = False\n",
    "    :param verbose: It controls whether the searching history will be printed. \n",
    "\n",
    "    Examples\n",
    "    ----------\n",
    "    >>> from sklearn import svm\n",
    "    >>> from sklearn import datasets\n",
    "    >>> from SeqMM.pyBayOpt.sktpe import TPESklearn\n",
    "    >>> from sklearn.model_selection import KFold\n",
    "    >>> iris = datasets.load_iris()\n",
    "    >>> ParaSpace = {'C':{'Type': 'continuous', 'Range': [-6, 16], 'Wrapper': np.exp2}, \n",
    "               'gamma': {'Type': 'continuous', 'Range': [-16, 6], 'Wrapper': np.exp2}}\n",
    "    >>> estimator = svm.SVC()\n",
    "    >>> cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    >>> clf = TPESklearn(estimator, cv, ParaSpace, refit = True, verbose = True)\n",
    "    >>> clf.fit(iris.data, iris.target)\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    :ivar best_score_: float\n",
    "        The best average cv score among the evaluated trials.  \n",
    "\n",
    "    :ivar best_params_: dict\n",
    "        Parameters that reaches `best_score_`.\n",
    "\n",
    "    :ivar best_estimator_: \n",
    "        The estimator refitted based on the `best_params_`. \n",
    "        Not available if `refit=False`.\n",
    "\n",
    "    :ivar search_time_consumed_: float\n",
    "        Seconds used for whole searching procedure.\n",
    "\n",
    "    :ivar refit_time_: float\n",
    "        Seconds used for refitting the best model on the whole dataset.\n",
    "        Not available if `refit=False`.\n",
    "    \"\"\"    \n",
    "\n",
    "    def __init__(self, estimator, cv, para_space, level_number = 20, max_runs = 100, \n",
    "                 scoring=None, n_jobs=None, refit=False, rand_seed = 0, verbose=False):\n",
    "\n",
    "        self.estimator = estimator        \n",
    "        self.cv = cv\n",
    "        \n",
    "        self.para_space = para_space\n",
    "        self.rand_seed = rand_seed\n",
    "        self.level_number = level_number\n",
    "        self.max_runs = max_runs\n",
    "\n",
    "        self.n_jobs = n_jobs\n",
    "        self.refit = refit\n",
    "        self.scoring = scoring\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.iteration = 0\n",
    "        self.logs = pd.DataFrame()\n",
    "        \n",
    "        self.para_ud_names = []\n",
    "        self.variable_number = [0]\n",
    "        self.factor_number = len(self.para_space)\n",
    "        self.para_names = list(self.para_space.keys())\n",
    "        for items, values in self.para_space.items():\n",
    "            if (values['Type']==\"categorical\"):\n",
    "                self.variable_number.append(len(values['Mapping']))\n",
    "                self.para_ud_names.extend([items + \"_UD_\" + str(i+1) for i in range(len(values['Mapping']))])\n",
    "            else:\n",
    "                self.variable_number.append(1)\n",
    "                self.para_ud_names.append(items+ \"_UD\")\n",
    "        self.extend_factor_number = sum(self.variable_number)  \n",
    "\n",
    "    def plot_scores(self):\n",
    "        \"\"\"\n",
    "        Visualize the scores history.\n",
    "        \"\"\"\n",
    "        if self.logs.shape[0]>0:\n",
    "            cum_best_score = self.logs[\"score\"].cummax()\n",
    "            fig = plt.figure(figsize = (6,4))\n",
    "            plt.plot(cum_best_score)\n",
    "            plt.xlabel('# of Runs')\n",
    "            plt.ylabel('Best Scores')\n",
    "            plt.title('The best found scores during optimization')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No available logs!\")\n",
    "            \n",
    "    def _summary(self):\n",
    "        \"\"\"\n",
    "        This function summarizes the evaluation results and makes records. \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        self.best_index_ = self.logs.loc[:,\"score\"].idxmax()\n",
    "        self.best_params_ = {self.logs.loc[:,self.para_names].columns[j]:\\\n",
    "                             self.logs.loc[:,self.para_names].iloc[self.best_index_,j] \n",
    "                              for j in range(self.logs.loc[:,self.para_names].shape[1])}\n",
    "        \n",
    "        self.best_score_ = self.logs.loc[:,\"score\"].iloc[self.best_index_]\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Search completed in %.2f seconds.\"%self.search_time_consumed_)\n",
    "            print(\"The best score is: %.5f.\"%self.best_score_)\n",
    "            print(\"The best configurations are:\")\n",
    "            print(\"\\n\".join(\"%-20s: %s\"%(k, v if self.para_space[k]['Type']==\"categorical\" else round(v, 5))\n",
    "                            for k, v in self.best_params_.items()))\n",
    "\n",
    "    def _para_mapping(self, para_set_ud):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function maps trials points in UD space ([0, 1]) to original scales. \n",
    "        \n",
    "        There are three types of variables: \n",
    "          - continuousï¼šPerform inverse Maxmin scaling for each value. \n",
    "          - integer: Evenly split the UD space, and map each partition to the corresponding integer values. \n",
    "          - categorical: The UD space uses one-hot encoding, and this function selects the one with the maximal value as class label.\n",
    "          \n",
    "        Parameters\n",
    "        ----------\n",
    "        para_set_ud: A pandas dataframe where each row represents a UD trial point, \n",
    "                and columns are used to represent variables. \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        para_set: The transformed variables.\n",
    "        \"\"\"\n",
    "        \n",
    "        para_set = pd.DataFrame(np.zeros((para_set_ud.shape[0],self.factor_number)), columns = self.para_names) \n",
    "        for items, values in self.para_space.items():\n",
    "            if (values['Type']==\"continuous\"):\n",
    "                para_set[items] = values['Wrapper'](para_set_ud[items+\"_UD\"]*(values['Range'][1]-values['Range'][0])+values['Range'][0])\n",
    "            elif (values['Type'] == \"integer\"):\n",
    "                temp = np.linspace(0, 1, len(values['Mapping'])+1)\n",
    "                for j in range(1,len(temp)):\n",
    "                    para_set.loc[(para_set_ud[items+\"_UD\"]>=temp[j-1])&(para_set_ud[items+\"_UD\"]<temp[j]),items] = values['Mapping'][j-1]\n",
    "                para_set.loc[para_set_ud[items+\"_UD\"]==1,items] = values['Mapping'][-1]\n",
    "                para_set[items] = para_set[items].round().astype(int)\n",
    "            elif (values['Type'] == \"categorical\"):\n",
    "                column_bool = [items in para_name for para_name in self.para_ud_names]\n",
    "                col_index = np.argmax(para_set_ud.loc[:,column_bool].values, axis = 1).tolist()\n",
    "                para_set[items] = np.array(values['Mapping'])[col_index]\n",
    "        return para_set  \n",
    "\n",
    "    def _lhs_run(self, obj_func):\n",
    "        \"\"\"\n",
    "        Main loop for searching the best hyperparameters. \n",
    "        \n",
    "        \"\"\"        \n",
    "        para_set_ud = lhs(n = self.extend_factor_number, samples = self.level_number, criterion='centermaximin')\n",
    "        para_set_ud = pd.DataFrame(para_set_ud, columns = self.para_ud_names)\n",
    "        para_set = self._para_mapping(para_set_ud)\n",
    "        para_set_ud.columns = self.para_ud_names\n",
    "        candidate_params = [{para_set.columns[j]: para_set.iloc[i,j] \n",
    "                             for j in range(para_set.shape[1])} \n",
    "                            for i in range(para_set.shape[0])] \n",
    "        out = Parallel(n_jobs=self.n_jobs)(delayed(obj_func)(parameters)\n",
    "                                for parameters in candidate_params)\n",
    "        self.logs = para_set_ud.to_dict()\n",
    "        self.logs.update(para_set)\n",
    "        self.logs.update(pd.DataFrame(out, columns = [\"score\"]))\n",
    "        self.logs = pd.DataFrame(logs_aug).reset_index(drop=True)\n",
    "        if self.verbose:\n",
    "            print(\"Stage %d completed (%d/%d) with best score: %.5f.\"\n",
    "                %(self.stage, self.logs.shape[0], self.max_runs, self.logs[\"score\"].max()))\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        \"\"\"\n",
    "        Run fit with all sets of parameters.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        :type x: array, shape = [n_samples, n_features] \n",
    "        :param x: input variales.\n",
    "        \n",
    "        :type y: array, shape = [n_samples] or [n_samples, n_output], optional\n",
    "        :param y: target variable.\n",
    "        \"\"\"\n",
    "        def obj_func(parameters):\n",
    "            self.estimator.set_params(**parameters)\n",
    "            out = cross_val_score(self.estimator, x, y, cv = self.cv, scoring = self.scoring)\n",
    "            score = np.mean(out)\n",
    "        \n",
    "        search_start_time = time.time()\n",
    "        self._lhs_run(obj_func)\n",
    "        search_end_time = time.time()\n",
    "        self.search_time_consumed_ = search_end_time - search_start_time\n",
    "       \n",
    "        self._summary()\n",
    "        if self.refit:\n",
    "            self.best_estimator_ = self.estimator.set_params(**self.best_params_)\n",
    "            refit_start_time = time.time()\n",
    "            if y is not None:\n",
    "                self.best_estimator_.fit(x, y)\n",
    "            else:\n",
    "                self.best_estimator_.fit(x)\n",
    "            refit_end_time = time.time()\n",
    "            self.refit_time_ = refit_end_time - refit_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "iris = datasets.load_iris()\n",
    "ParaSpace = {'C':{'Type': 'continuous', 'Range': [-6, 16], 'Wrapper': np.exp2}, \n",
    "       'gamma': {'Type': 'continuous', 'Range': [-16, 6], 'Wrapper': np.exp2}}\n",
    "Level_Number = 20\n",
    "estimator = svm.SVC()\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "clf = LHSSklearn(estimator, cv, ParaSpace, Level_Number, n_jobs = 10, refit = True, verbose = True)\n",
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
